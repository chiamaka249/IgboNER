{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Practice of Copy of igbobert4",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiamaka249/IgboNER/blob/main/Practice_of_Copy_of_igbobert4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSkvlYoplYP"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "def unzip(zipfilename):\n",
        "  try:\n",
        "    with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(zipfilename[:-4])\n",
        "      return f\"'{zipfilename}' unzipped!\"\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Cannot find '{zipfilename}' file\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLhNvJubEowT"
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "# transformers version at notebook update --- 2.11.0\n",
        "# tokenizers version at notebook update --- 0.8.0rc1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekvedLrFR_t"
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./igbo_bert4/vocab.json\",\n",
        "    \"./igbo_bert4/merges.txt\",\n",
        ")\n",
        "\n",
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip('/content/gdrive/MyDrive/igbo_bert/igbo_bert3.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "35pA_5xG1pbk",
        "outputId": "eb37c25e-4369-48b2-d3f5-d34b42248b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'/content/gdrive/MyDrive/igbo_bert/igbo_bert3.zip' unzipped!\""
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "working_dir='/content/gdrive/MyDrive/igbo_bert/igbo_bert3'"
      ],
      "metadata": {
        "id": "HQy8cjqJ0P6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(working_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWR4fexS1Fpn",
        "outputId": "660b4d66-02e2-4a1a-bd7a-e1dfcab80e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['checkpoint-10000',\n",
              " 'runs',\n",
              " 'config.json',\n",
              " 'pytorch_model.bin',\n",
              " 'vocab.json',\n",
              " 'merges.txt',\n",
              " 'training_args.bin']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(working_dir, max_len=512)"
      ],
      "metadata": {
        "id": "taHJkUJ70CEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nm7h9ndFis2",
        "outputId": "cc821b8f-6f52-4478-b9b3-a3ee8793244a"
      },
      "source": [
        "tokenizer.encode(\"Simone gara ụka ụnyahụ guọ egwu ma ga-kwa taa.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 39426, 755, 1123, 7384, 1367, 265, 686, 313, 311, 17, 315, 837, 18, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtbKfFgG-Y3"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvup7wl8Hhp9"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyWUosTlHnRE",
        "outputId": "1093a153-a2ac-40e9-899b-de2107437eaf"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 83 million parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(os.path.join(working_dir, 'pytorch_model.bin')))"
      ],
      "metadata": {
        "id": "a7K51JshhawR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_pretrained_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "RU26qug-9iE0",
        "outputId": "2d70980a-8187-4d7b-8acc-4d0511157c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 39.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 38.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 123 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.20.23-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 79.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.24.0,>=1.23.23\n",
            "  Downloading botocore-1.23.23-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 54.5 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.23->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 78.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.23->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 75.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.23 botocore-1.23.23 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkwVjpAyIVu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11846483-2d91-4e83-a1aa-1becbeb9e571"
      },
      "source": [
        "trainer.save_model(\"./igbo_bert4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert4\n",
            "Configuration saved in ./igbo_bert4/config.json\n",
            "Model weights saved in ./igbo_bert4/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYx9FK7ZIYZs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1000e6a8-300b-43cd-aed2-491de693b5af"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./igbo_bert4\",\n",
        "    tokenizer=\"./igbo_bert4\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading weights file ./igbo_bert4/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./igbo_bert4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "Didn't find file ./igbo_bert4/vocab.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/merges.txt. We won't load it.\n",
            "Didn't find file ./igbo_bert4/tokenizer.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/added_tokens.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/special_tokens_map.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/tokenizer_config.json. We won't load it.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f95277eb11e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"fill-mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./igbo_bert4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./igbo_bert4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             tokenizer = AutoTokenizer.from_pretrained(\n\u001b[0;32m--> 557\u001b[0;31m                 \u001b[0mtokenizer_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             )\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1731\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"- or '{revision}' is a valid git identifier (branch name, a tag name, or a commit id) that exists for this model name as listed on its model page on 'https://huggingface.co/models'\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for './igbo_bert4'. Make sure that:\n\n- './igbo_bert4' is a correct model identifier listed on 'https://huggingface.co/models'\n  (make sure './igbo_bert4' is not a path to a local directory with something else, in that case)\n\n- or './igbo_bert4' is the correct path to a directory containing relevant tokenizer files\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQK6jyf9IkRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee07d65-4f62-4d0b-f886-3bf27c643ab8"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Abụ m Maazị <mask>.\") #= okafor/Ọkafọ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.013978319242596626,\n",
              "  'sequence': 'Abụ m Maazị Ọkafọ.',\n",
              "  'token': 5775,\n",
              "  'token_str': ' Ọkafọ'},\n",
              " {'score': 0.010930763557553291,\n",
              "  'sequence': 'Abụ m Maazị O.',\n",
              "  'token': 378,\n",
              "  'token_str': ' O'},\n",
              " {'score': 0.01065503153949976,\n",
              "  'sequence': 'Abụ m Maazị Obianọ.',\n",
              "  'token': 1566,\n",
              "  'token_str': ' Obianọ'},\n",
              " {'score': 0.00977820809930563,\n",
              "  'sequence': 'Abụ m Maazị M.',\n",
              "  'token': 398,\n",
              "  'token_str': ' M'},\n",
              " {'score': 0.0066724903881549835,\n",
              "  'sequence': 'Abụ m Maazị E.',\n",
              "  'token': 426,\n",
              "  'token_str': ' E'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mje0nMIoWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773f5d2f-5d16-4c7f-825f-308271b7e9ac"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaanyị na <mask> ji na akara.\") #= eri\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.12062991410493851,\n",
              "  'sequence': 'Nwaanyị na ya ji na akara.',\n",
              "  'token': 290,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.04657674953341484,\n",
              "  'sequence': 'Nwaanyị na nwunye ji na akara.',\n",
              "  'token': 740,\n",
              "  'token_str': ' nwunye'},\n",
              " {'score': 0.023468855768442154,\n",
              "  'sequence': 'Nwaanyị na nna ji na akara.',\n",
              "  'token': 723,\n",
              "  'token_str': ' nna'},\n",
              " {'score': 0.02191004902124405,\n",
              "  'sequence': 'Nwaanyị na ha ji na akara.',\n",
              "  'token': 297,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.021505558863282204,\n",
              "  'sequence': 'Nwaanyị na nwaanyị ji na akara.',\n",
              "  'token': 629,\n",
              "  'token_str': ' nwaanyị'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9wjE8PItpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc319676-dbcb-41a1-8bf4-4d0c551a66b0"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Chineke ga- ebibikwa ndị niile na- eme ihe <mask>.\") #=ọjọọ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.3927464187145233,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ọjọọ.',\n",
              "  'token': 726,\n",
              "  'token_str': ' ọjọọ'},\n",
              " {'score': 0.13551250100135803,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ọma.',\n",
              "  'token': 503,\n",
              "  'token_str': ' ọma'},\n",
              " {'score': 0.06629031151533127,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe a.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.06092679873108864,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe niile.',\n",
              "  'token': 434,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.031389206647872925,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ike.',\n",
              "  'token': 363,\n",
              "  'token_str': ' ike'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubR7pCxJIyNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14301b9-55f0-4744-b66e-b16f582e086f"
      },
      "source": [
        "fill_mask(\"ọba akwụkwọ Ọkammụta Kenneth Dike dị <mask>.\") #n'Awka\n",
        "\n",
        "# This is the beginning of a beautiful <mask>.\n",
        "# =>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.14023567736148834,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị iche.',\n",
              "  'token': 447,\n",
              "  'token_str': ' iche'},\n",
              " {'score': 0.07257493585348129,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị icheiche.',\n",
              "  'token': 3871,\n",
              "  'token_str': ' icheiche'},\n",
              " {'score': 0.07037945091724396,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị nso.',\n",
              "  'token': 606,\n",
              "  'token_str': ' nso'},\n",
              " {'score': 0.042156368494033813,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị ugbua.',\n",
              "  'token': 1350,\n",
              "  'token_str': ' ugbua'},\n",
              " {'score': 0.04174605384469032,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị egwu.',\n",
              "  'token': 703,\n",
              "  'token_str': ' egwu'}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgveMBQYNZV7",
        "outputId": "7048656e-bc72-4c7f-dfc3-a5ab727a82fb"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaanyị na eri <mask> na akara.\") #= ji\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.13028940558433533,\n",
              "  'sequence': 'Nwaanyị na eri ya na akara.',\n",
              "  'token': 290,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.05488795042037964,\n",
              "  'sequence': 'Nwaanyị na eri nri na akara.',\n",
              "  'token': 885,\n",
              "  'token_str': ' nri'},\n",
              " {'score': 0.02480449341237545,\n",
              "  'sequence': 'Nwaanyị na eri ihe na akara.',\n",
              "  'token': 304,\n",
              "  'token_str': ' ihe'},\n",
              " {'score': 0.019163204357028008,\n",
              "  'sequence': 'Nwaanyị na eri ọkụ na akara.',\n",
              "  'token': 707,\n",
              "  'token_str': ' ọkụ'},\n",
              " {'score': 0.017493773251771927,\n",
              "  'sequence': 'Nwaanyị na eri m na akara.',\n",
              "  'token': 268,\n",
              "  'token_str': ' m'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRbvsFIyNpID",
        "outputId": "17053230-b060-42bb-aac8-8fb116cef776"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ọ bụ <mask>a ka a na- arịa .\") #= mmadụ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.22005508840084076,\n",
              "  'sequence': 'Ọ bụ-a ka a na- arịa.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.019461117684841156,\n",
              "  'sequence': 'Ọ bụ Nwannaa ka a na- arịa.',\n",
              "  'token': 1546,\n",
              "  'token_str': ' Nwanna'},\n",
              " {'score': 0.008462444879114628,\n",
              "  'sequence': 'Ọ bụ ‘a ka a na- arịa.',\n",
              "  'token': 531,\n",
              "  'token_str': ' ‘'},\n",
              " {'score': 0.0064787482842803,\n",
              "  'sequence': 'Ọ bụ yaa ka a na- arịa.',\n",
              "  'token': 290,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.006270089186728001,\n",
              "  'sequence': 'Ọ bụ ụmụa ka a na- arịa.',\n",
              "  'token': 428,\n",
              "  'token_str': ' ụmụ'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6O-Q8D7g5eY"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOLSz2YI4Rv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e771839-14ef-4956-b021-3d815ef2ad60"
      },
      "source": [
        "shutil.make_archive(\"/content/igbo_bert4\", 'zip', \"igbo_bert4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/igbo_bert4.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hddc-BufgXzf",
        "outputId": "a4ead454-8ab4-48ca-f58c-ecbf54a1c363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = '/igbo_bert4.zip'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "vfeHNovnVuNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX7kbLAcJJ6I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "de0575e6-7467-48f4-b5c4-6319e410f243"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/igbo_bert4.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d2312e7c6393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/igbo_bert2.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/igbo_bert2.zip"
          ]
        }
      ]
    }
  ]
}