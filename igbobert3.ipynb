{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "igbobert3",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP0WOB8PEqjHcc1SYjrLXWE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiamaka249/IgboNER/blob/main/igbobert3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLstc8Tt6egI"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJSw3sQyBbmV"
      },
      "source": [
        "with open(\"/content/Iglacuna.txt\") as f:\n",
        "  lacuna_text = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLhNvJubEowT",
        "outputId": "202ac9a8-2c06-4211-feee-44b064043cac"
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "# transformers version at notebook update --- 2.11.0\n",
        "# tokenizers version at notebook update --- 0.8.0rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Successfully uninstalled tensorflow-2.7.0\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-4168yyuj\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-4168yyuj\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 49.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 665 kB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3254235 sha256=2981594d925fc7b680d76029ebe8e80e172b4dc4cc0912487ea480ea42c409b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_03nrq68/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.0 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0.dev0\n",
            "tokenizers                    0.10.3\n",
            "transformers                  4.13.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyraD86RE3QK",
        "outputId": "5b0c8e77-66df-4d33-f4ab-71bf91c65785"
      },
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.1 s, sys: 1.24 s, total: 18.3 s\n",
            "Wall time: 5.13 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro52g8BqFFfr",
        "outputId": "6cbb24ae-8f8d-41b8-eb12-b8d6b609c27d"
      },
      "source": [
        "!mkdir igbo_bert3\n",
        "tokenizer.save_model(\"igbo_bert3\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['igbo_bert3/vocab.json', 'igbo_bert3/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekvedLrFR_t"
      },
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./igbo_bert3/vocab.json\",\n",
        "    \"./igbo_bert3/merges.txt\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E52LgvLWFbuq"
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nm7h9ndFis2",
        "outputId": "7613b3e3-3325-4c06-f182-eb17467a431e"
      },
      "source": [
        "tokenizer.encode(\"Simone gara akwụkwọ taa.\").tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'Simone', 'Ġgara', 'Ġakwá»¥kwá»į', 'Ġtaa', '.', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxcYhcxRKROn",
        "outputId": "29fd14c5-d1f5-4a15-f52c-942cc5486447"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  2 14:51:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMe5vRLvG5Zb",
        "outputId": "6e4c2fc3-1d04-45c2-82d4-369eac6c056c"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtbKfFgG-Y3"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhCRKUJR65iJ"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqujlqjHQnX"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./igbo_bert3\", max_len=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvup7wl8Hhp9"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyWUosTlHnRE",
        "outputId": "6638df31-c5ed-41f1-ba75-56c4d9d314a0"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 83 million parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hujpbn1oHp-x",
        "outputId": "e1ed42ca-414b-4d3b-abdd-646d29d6ea9e"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = \"/content/Iglacuna.txt\",\n",
        "    block_size = 128\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.9 s, sys: 1.18 s, total: 34.1 s\n",
            "Wall time: 15.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EICtSzqwH618"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kalucrRPH9wb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./igbo_bert3\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vCWG7CRZIOkb",
        "outputId": "28167a99-825d-4956-c54b-00473d499d72"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "***** Running training *****\n",
            "  Num examples = 391448\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 18351\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4743' max='18351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4743/18351 42:33 < 2:02:08, 1.86 it/s, Epoch 0.78/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.337600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.856400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.520100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.309400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>4.130600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>4.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.885200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.793900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18351' max='18351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18351/18351 2:32:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.337600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.856400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.520100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.309400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>4.130600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>4.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.885200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.793900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.719800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>3.632700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.619500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>3.548200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>3.460200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>3.398300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>3.367800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>3.346400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>3.301800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>3.244800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>3.258900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>3.203300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>3.173700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>3.150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>3.127900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>3.101800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>3.106500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>3.068100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>3.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>3.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>3.047700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>3.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>3.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>2.993500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>2.980700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>2.991700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>2.976700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert3/checkpoint-10000\n",
            "Configuration saved in ./igbo_bert3/checkpoint-10000/config.json\n",
            "Model weights saved in ./igbo_bert3/checkpoint-10000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 50min 26s, sys: 42min 54s, total: 2h 33min 21s\n",
            "Wall time: 2h 32min 54s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=18351, training_loss=3.5481224906106106, metrics={'train_runtime': 9174.2898, 'train_samples_per_second': 128.004, 'train_steps_per_second': 2.0, 'total_flos': 2.0182020568559616e+16, 'train_loss': 3.5481224906106106, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkwVjpAyIVu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d96d11a-0374-4416-8892-9cbda746c346"
      },
      "source": [
        "trainer.save_model(\"./igbo_bert3\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert3\n",
            "Configuration saved in ./igbo_bert3/config.json\n",
            "Model weights saved in ./igbo_bert3/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYx9FK7ZIYZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e249ea7-7627-4579-bc2a-aa9b5c8a2683"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./igbo_bert3\",\n",
        "    tokenizer=\"./igbo_bert3\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./igbo_bert3/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert3\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert3/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert3\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading weights file ./igbo_bert3/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./igbo_bert3.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file ./igbo_bert3/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert3\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "Didn't find file ./igbo_bert3/tokenizer.json. We won't load it.\n",
            "Didn't find file ./igbo_bert3/added_tokens.json. We won't load it.\n",
            "Didn't find file ./igbo_bert3/special_tokens_map.json. We won't load it.\n",
            "Didn't find file ./igbo_bert3/tokenizer_config.json. We won't load it.\n",
            "loading file ./igbo_bert3/vocab.json\n",
            "loading file ./igbo_bert3/merges.txt\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading configuration file ./igbo_bert3/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert3\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert3/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert3\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQK6jyf9IkRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be8d2fe-bdf8-4d6b-9196-535fccc16abb"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Abụ m Maazị <mask>.\") #= okafor/Ọkafọ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.021709423512220383,\n",
              "  'sequence': 'Abụ m Maazị A.',\n",
              "  'token': 348,\n",
              "  'token_str': ' A'},\n",
              " {'score': 0.01375269703567028,\n",
              "  'sequence': 'Abụ m Maazị O.',\n",
              "  'token': 382,\n",
              "  'token_str': ' O'},\n",
              " {'score': 0.009152992628514767,\n",
              "  'sequence': 'Abụ m Maazị Ha.',\n",
              "  'token': 968,\n",
              "  'token_str': ' Ha'},\n",
              " {'score': 0.008712009526789188,\n",
              "  'sequence': 'Abụ m Maazị M.',\n",
              "  'token': 398,\n",
              "  'token_str': ' M'},\n",
              " {'score': 0.007407011929899454,\n",
              "  'sequence': 'Abụ m Maazị Ya.',\n",
              "  'token': 1240,\n",
              "  'token_str': ' Ya'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mje0nMIoWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d50008-5f4b-44ca-82bb-7e5879bcdb97"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaanyị na <mask> ji na akara.\") #= eri\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.11575991660356522,\n",
              "  'sequence': 'Nwaanyị na ya ji na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.07262290269136429,\n",
              "  'sequence': 'Nwaanyị na e ji na akara.',\n",
              "  'token': 271,\n",
              "  'token_str': ' e'},\n",
              " {'score': 0.058269668370485306,\n",
              "  'sequence': 'Nwaanyị na ha ji na akara.',\n",
              "  'token': 298,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.0558326356112957,\n",
              "  'sequence': 'Nwaanyị na o ji na akara.',\n",
              "  'token': 273,\n",
              "  'token_str': ' o'},\n",
              " {'score': 0.02874232828617096,\n",
              "  'sequence': 'Nwaanyị na- ji na akara.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9wjE8PItpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130a7feb-7cee-4db3-c9a3-f854de8a056b"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Chineke ga- ebibikwa ndị niile na- eme ihe <mask>.\") #=ọjọọ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.22356781363487244,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ọma.',\n",
              "  'token': 508,\n",
              "  'token_str': ' ọma'},\n",
              " {'score': 0.14048273861408234,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ọjọọ.',\n",
              "  'token': 717,\n",
              "  'token_str': ' ọjọọ'},\n",
              " {'score': 0.1313692182302475,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe niile.',\n",
              "  'token': 431,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.12606249749660492,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe a.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.031202223151922226,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ahụ.',\n",
              "  'token': 309,\n",
              "  'token_str': ' ahụ'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubR7pCxJIyNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb22e575-8f52-4857-b29f-54b88452c052"
      },
      "source": [
        "fill_mask(\"O riri <mask>.\")\n",
        "\n",
        "# This is the beginning of a beautiful <mask>.\n",
        "# =>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.4518226385116577,\n",
              "  'sequence': 'O riri ya.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.18243154883384705,\n",
              "  'sequence': 'O riri ha.',\n",
              "  'token': 298,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.031142286956310272,\n",
              "  'sequence': 'O riri anya.',\n",
              "  'token': 405,\n",
              "  'token_str': ' anya'},\n",
              " {'score': 0.022876620292663574,\n",
              "  'sequence': 'O riri aka.',\n",
              "  'token': 387,\n",
              "  'token_str': ' aka'},\n",
              " {'score': 0.01775292120873928,\n",
              "  'sequence': 'O riri ihe.',\n",
              "  'token': 302,\n",
              "  'token_str': ' ihe'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgveMBQYNZV7",
        "outputId": "323510ea-cc40-4319-80e9-efe9431ff77b"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaanyị na eri <mask> na akara.\") #= ji\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1460145264863968,\n",
              "  'sequence': 'Nwaanyị na eri ya na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.031209174543619156,\n",
              "  'sequence': 'Nwaanyị na eri aka na akara.',\n",
              "  'token': 387,\n",
              "  'token_str': ' aka'},\n",
              " {'score': 0.02808999828994274,\n",
              "  'sequence': 'Nwaanyị na eri ahụ na akara.',\n",
              "  'token': 309,\n",
              "  'token_str': ' ahụ'},\n",
              " {'score': 0.016127975657582283,\n",
              "  'sequence': 'Nwaanyị na eri ihe na akara.',\n",
              "  'token': 302,\n",
              "  'token_str': ' ihe'},\n",
              " {'score': 0.015274378471076488,\n",
              "  'sequence': 'Nwaanyị na eri ha na akara.',\n",
              "  'token': 298,\n",
              "  'token_str': ' ha'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRbvsFIyNpID",
        "outputId": "70b1fde0-a014-4481-ac34-f31b1e807425"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaanyị na eri ji na <mask>.\") #= akara\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.10732906311750412,\n",
              "  'sequence': 'Nwaanyị na eri ji na ya.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.02028745226562023,\n",
              "  'sequence': 'Nwaanyị na eri ji na-.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.016717415302991867,\n",
              "  'sequence': 'Nwaanyị na eri ji na jw.',\n",
              "  'token': 4467,\n",
              "  'token_str': ' jw'},\n",
              " {'score': 0.014438007026910782,\n",
              "  'sequence': 'Nwaanyị na eri ji na Betel.',\n",
              "  'token': 2335,\n",
              "  'token_str': ' Betel'},\n",
              " {'score': 0.013661667704582214,\n",
              "  'sequence': 'Nwaanyị na eri ji na Jeruselem.',\n",
              "  'token': 1083,\n",
              "  'token_str': ' Jeruselem'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6O-Q8D7g5eY"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOLSz2YI4Rv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3233397-8ced-4f28-9959-586e8d925625"
      },
      "source": [
        "shutil.make_archive(\"/content/igbo_bert3\", 'zip', \"igbo_bert3\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/igbo_bert3.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX7kbLAcJJ6I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "de0575e6-7467-48f4-b5c4-6319e410f243"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/igbo_bert3.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d2312e7c6393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/igbo_bert2.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/igbo_bert2.zip"
          ]
        }
      ]
    }
  ]
}