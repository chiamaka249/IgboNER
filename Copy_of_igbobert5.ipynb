{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of  igbobert5",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM4gAVIMMjJzwq7WTxR3Zvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiamaka249/IgboNER/blob/main/Copy_of_igbobert5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4amslz4Oo9vT",
        "outputId": "a2f999dd-2863-41e2-bd44-da658ecbbd15"
      },
      "source": [
        "!wget -c https://github.com/IgnatiusEzeani/IGBONLP/raw/master/ig_monoling/text.zip\n",
        "!wget -c https://raw.githubusercontent.com/chiamaka249/lacuna_pos_ner/main/language_corpus/ibo/ibo.txt\n",
        "# !wget -c https://github.com/chiamaka249/IgboNER/blob/main/config.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 13:55:37--  https://github.com/IgnatiusEzeani/IGBONLP/raw/master/ig_monoling/text.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/IgnatiusEzeani/IGBONLP/master/ig_monoling/text.zip [following]\n",
            "--2021-12-10 13:55:37--  https://raw.githubusercontent.com/IgnatiusEzeani/IGBONLP/master/ig_monoling/text.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7604282 (7.3M) [application/zip]\n",
            "Saving to: ‚Äòtext.zip‚Äô\n",
            "\n",
            "text.zip            100%[===================>]   7.25M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-12-10 13:55:37 (86.9 MB/s) - ‚Äòtext.zip‚Äô saved [7604282/7604282]\n",
            "\n",
            "--2021-12-10 13:55:37--  https://raw.githubusercontent.com/chiamaka249/lacuna_pos_ner/main/language_corpus/ibo/ibo.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1908788 (1.8M) [text/plain]\n",
            "Saving to: ‚Äòibo.txt‚Äô\n",
            "\n",
            "ibo.txt             100%[===================>]   1.82M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-12-10 13:55:38 (31.6 MB/s) - ‚Äòibo.txt‚Äô saved [1908788/1908788]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSkvlYoplYP"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "def unzip(zipfilename):\n",
        "  try:\n",
        "    with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(zipfilename[:-4])\n",
        "      return f\"'{zipfilename}' unzipped!\"\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Cannot find '{zipfilename}' file\")\n",
        "\n",
        "unzip(\"text.zip\")\n",
        "!rm text.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua0R2p31p8zA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef839b9b-32a6-468c-f985-5ac8e5f55f6d"
      },
      "source": [
        "#copies the file \"ibo.txt\" to into the folder \"text\"\n",
        "import shutil\n",
        "shutil.copy('/content/ibo.txt', '/content/text')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/text/ibo.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj4i2-9bp4U3"
      },
      "source": [
        "# import os\n",
        "#import shutil\n",
        "dir_name = \"/content/text\"\n",
        "text=\"\"\n",
        "for fname in os.listdir(dir_name):\n",
        "  fname = os.path.join(dir_name, fname)\n",
        "  with open(fname, \"r\", encoding=\"utf8\") as datafile:\n",
        "    text = text+\"\\n\"+datafile.read()\n",
        "\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf8\") as datafile:\n",
        "  datafile.write(text)\n",
        "\n",
        "shutil.rmtree(\"text\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLhNvJubEowT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c67461a-95ed-4504-ae57-d5b0b014115a"
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "# transformers version at notebook update --- 2.11.0\n",
        "# tokenizers version at notebook update --- 0.8.0rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Successfully uninstalled tensorflow-2.7.0\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-7hq954v8\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-7hq954v8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61 kB 435 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.8.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.14.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.14.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.14.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.14.0.dev0-py3-none-any.whl size=3320694 sha256=ea466d0c77aee645aff42d3c4687f0ad0ca7ee78eebe49164f31b39d9d9ca629\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h4tuxkfa/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.0.dev0\n",
            "tokenizers                    0.10.3\n",
            "transformers                  4.14.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyraD86RE3QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aea01cd-c4dd-474d-8130-5c0950d262cf"
      },
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 24.8 s, sys: 1.74 s, total: 26.5 s\n",
            "Wall time: 7.34 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro52g8BqFFfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5198ef5-d44e-4434-ae6f-0bc21e563133"
      },
      "source": [
        "!mkdir igbo_bert4\n",
        "tokenizer.save_model(\"igbo_bert4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['igbo_bert4/vocab.json', 'igbo_bert4/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekvedLrFR_t"
      },
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./igbo_bert4/vocab.json\",\n",
        "    \"./igbo_bert4/merges.txt\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E52LgvLWFbuq"
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nm7h9ndFis2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834dc88f-bdd7-4bb8-8f6b-7cce7b2e38f1"
      },
      "source": [
        "tokenizer.encode(\"Simone gara ·ª•ka ·ª•nyah·ª• gu·ªç egwu ma ga-kwa taa.\").tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'Simone',\n",
              " 'ƒ†gara',\n",
              " 'ƒ†√°¬ª¬•ka',\n",
              " 'ƒ†√°¬ª¬•nyah√°¬ª¬•',\n",
              " 'ƒ†gu',\n",
              " '√°¬ªƒØ',\n",
              " 'ƒ†egwu',\n",
              " 'ƒ†ma',\n",
              " 'ƒ†ga',\n",
              " '-',\n",
              " 'kwa',\n",
              " 'ƒ†taa',\n",
              " '.',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxcYhcxRKROn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0408ac-7239-4b1d-b4e9-3776e4e2828e"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 10 14:01:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMe5vRLvG5Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8986bdbc-184c-4ebd-e496-7ec3f64edcf6"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtbKfFgG-Y3"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhCRKUJR65iJ"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqujlqjHQnX"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./igbo_bert4\", max_len=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvup7wl8Hhp9"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyWUosTlHnRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7247292-4df1-422c-dad0-4a8746268ff0"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 83 million parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hujpbn1oHp-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d75f3ec-a21a-4634-c2b6-45c13f779c7c"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = \"/content/data.txt\",\n",
        "    block_size = 128\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 42.2 s, sys: 1.54 s, total: 43.8 s\n",
            "Wall time: 19.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EICtSzqwH618"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kalucrRPH9wb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./igbo_bert4\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCWG7CRZIOkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4a11f94-be9a-455c-80f4-e0f55c6fa501"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "***** Running training *****\n",
            "  Num examples = 391448\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 30585\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30585' max='30585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30585/30585 3:11:16, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.385000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.254600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.849400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.510000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.272500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>4.124000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>3.952800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.885700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.721500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.662000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>3.611200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.522600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>3.462000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>3.390500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>3.363000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>3.305200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>3.276500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>3.227800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>3.190100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>3.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>3.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>3.114400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>3.067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>3.051900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>3.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>3.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>2.965600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>2.927700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>2.924700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>2.928300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>2.879700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>2.885100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>2.849100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>2.848500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>2.809900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>2.817400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>2.771800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>2.772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>2.757900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>2.752300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>2.734300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>2.704000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>2.723300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>2.698500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>2.716500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>2.706700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>2.668500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>2.669400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>2.669800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>2.655500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>2.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>2.647900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>2.619100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>2.592800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>2.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>2.607300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>2.620600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>2.614900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>2.581700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>2.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>2.606100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert4/checkpoint-10000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-10000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-10000/pytorch_model.bin\n",
            "Saving model checkpoint to ./igbo_bert4/checkpoint-20000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-20000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-20000/pytorch_model.bin\n",
            "Saving model checkpoint to ./igbo_bert4/checkpoint-30000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-30000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-30000/pytorch_model.bin\n",
            "Deleting older checkpoint [igbo_bert4/checkpoint-10000] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3h 9min 10s, sys: 3min 21s, total: 3h 12min 31s\n",
            "Wall time: 3h 11min 17s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30585, training_loss=3.1476998701309173, metrics={'train_runtime': 11477.3182, 'train_samples_per_second': 170.531, 'train_steps_per_second': 2.665, 'total_flos': 3.357401044877568e+16, 'train_loss': 3.1476998701309173, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkwVjpAyIVu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a1ab72-142e-402c-8564-05fb31a8a1e5"
      },
      "source": [
        "trainer.save_model(\"./igbo_bert4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert4\n",
            "Configuration saved in ./igbo_bert4/config.json\n",
            "Model weights saved in ./igbo_bert4/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYx9FK7ZIYZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0834511-7a1b-4f21-bd0a-d1484799808d"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./igbo_bert4\",\n",
        "    tokenizer=\"./igbo_bert4\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading weights file ./igbo_bert4/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./igbo_bert4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "Didn't find file ./igbo_bert4/tokenizer.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/added_tokens.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/special_tokens_map.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/tokenizer_config.json. We won't load it.\n",
            "loading file ./igbo_bert4/vocab.json\n",
            "loading file ./igbo_bert4/merges.txt\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQK6jyf9IkRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32bce663-8ec2-4108-d714-3c57ba96230b"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ab·ª• m Maaz·ªã <mask>.\") #= okafor/·ªåkaf·ªç\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.010340388864278793,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã A.',\n",
              "  'token': 347,\n",
              "  'token_str': ' A'},\n",
              " {'score': 0.009177258238196373,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã O.',\n",
              "  'token': 377,\n",
              "  'token_str': ' O'},\n",
              " {'score': 0.0053979880176484585,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã John.',\n",
              "  'token': 2772,\n",
              "  'token_str': ' John'},\n",
              " {'score': 0.005330500192940235,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã ·ªåkaf·ªç.',\n",
              "  'token': 5576,\n",
              "  'token_str': ' ·ªåkaf·ªç'},\n",
              " {'score': 0.005150600336492062,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã Nwaany·ªã.',\n",
              "  'token': 2822,\n",
              "  'token_str': ' Nwaany·ªã'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mje0nMIoWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641c4e00-40aa-4396-c486-c14b61593076"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #= eri\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1287631392478943,\n",
              "  'sequence': 'Nwaany·ªã na- ji na akara.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.11695194989442825,\n",
              "  'sequence': 'Nwaany·ªã na ya ji na akara.',\n",
              "  'token': 290,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.10842421650886536,\n",
              "  'sequence': 'Nwaany·ªã na nwunye ji na akara.',\n",
              "  'token': 732,\n",
              "  'token_str': ' nwunye'},\n",
              " {'score': 0.036929309368133545,\n",
              "  'sequence': 'Nwaany·ªã na nwaany·ªã ji na akara.',\n",
              "  'token': 620,\n",
              "  'token_str': ' nwaany·ªã'},\n",
              " {'score': 0.019814301282167435,\n",
              "  'sequence': 'Nwaany·ªã na nna ji na akara.',\n",
              "  'token': 717,\n",
              "  'token_str': ' nna'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9wjE8PItpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772925c7-e3a9-4747-8222-7282b27df1b7"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Chineke ga- ebibikwa nd·ªã niile na- eme ihe <mask>.\") #=·ªçj·ªç·ªç\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.29081615805625916,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ·ªçj·ªç·ªç.',\n",
              "  'token': 718,\n",
              "  'token_str': ' ·ªçj·ªç·ªç'},\n",
              " {'score': 0.13454636931419373,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ·ªçma.',\n",
              "  'token': 498,\n",
              "  'token_str': ' ·ªçma'},\n",
              " {'score': 0.06475759297609329,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe niile.',\n",
              "  'token': 430,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.04965321347117424,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe anya.',\n",
              "  'token': 402,\n",
              "  'token_str': ' anya'},\n",
              " {'score': 0.04515065252780914,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ike.',\n",
              "  'token': 362,\n",
              "  'token_str': ' ike'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubR7pCxJIyNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26f2636-8cca-4338-bad1-f2bf52a62401"
      },
      "source": [
        "fill_mask(\"·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã <mask>.\") #n'Awka\n",
        "\n",
        "# This is the beginning of a beautiful <mask>.\n",
        "# =>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.23585939407348633,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã iche.',\n",
              "  'token': 442,\n",
              "  'token_str': ' iche'},\n",
              " {'score': 0.06350675970315933,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã icheiche.',\n",
              "  'token': 3762,\n",
              "  'token_str': ' icheiche'},\n",
              " {'score': 0.061406027525663376,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã mkpa.',\n",
              "  'token': 614,\n",
              "  'token_str': ' mkpa'},\n",
              " {'score': 0.04727039113640785,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã ukwuu.',\n",
              "  'token': 1040,\n",
              "  'token_str': ' ukwuu'},\n",
              " {'score': 0.035409118980169296,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã nd·ª•.',\n",
              "  'token': 534,\n",
              "  'token_str': ' nd·ª•'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgveMBQYNZV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbb0a74-dcc0-4f82-c6a1-dea45423d498"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaany·ªã na eri <mask> na akara.\") #= ji\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.04619939625263214,\n",
              "  'sequence': 'Nwaany·ªã na eri nri na akara.',\n",
              "  'token': 873,\n",
              "  'token_str': ' nri'},\n",
              " {'score': 0.04371406137943268,\n",
              "  'sequence': 'Nwaany·ªã na eri ya na akara.',\n",
              "  'token': 290,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.034361857920885086,\n",
              "  'sequence': 'Nwaany·ªã na eri ihe na akara.',\n",
              "  'token': 302,\n",
              "  'token_str': ' ihe'},\n",
              " {'score': 0.02798701822757721,\n",
              "  'sequence': 'Nwaany·ªã na eri ego na akara.',\n",
              "  'token': 590,\n",
              "  'token_str': ' ego'},\n",
              " {'score': 0.025064406916499138,\n",
              "  'sequence': 'Nwaany·ªã na eri nwaany·ªã na akara.',\n",
              "  'token': 620,\n",
              "  'token_str': ' nwaany·ªã'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Gaan·ª• mee nd·ªã <mask> niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m  .\") #= mba\n"
      ],
      "metadata": {
        "id": "-JgRzOtZmTtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ff2d1e-a97d-459e-be8c-9836dc76820d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.4334820806980133,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã a niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.057006802409887314,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã mmad·ª• niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 389,\n",
              "  'token_str': ' mmad·ª•'},\n",
              " {'score': 0.054193347692489624,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã ·ªçz·ªç niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 434,\n",
              "  'token_str': ' ·ªçz·ªç'},\n",
              " {'score': 0.05103715509176254,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã okenye niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 1028,\n",
              "  'token_str': ' okenye'},\n",
              " {'score': 0.05098661035299301,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã Izrel niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 693,\n",
              "  'token_str': ' Izrel'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• <mask>.\") #= Izrel\n"
      ],
      "metadata": {
        "id": "_zB0aW-cmuQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426096f5-be5a-4ea6-e6bd-8eb52ceb491f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.46299779415130615,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• Izrel.',\n",
              "  'token': 693,\n",
              "  'token_str': ' Izrel'},\n",
              " {'score': 0.10745415091514587,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• mmad·ª•.',\n",
              "  'token': 389,\n",
              "  'token_str': ' mmad·ª•'},\n",
              " {'score': 0.10136278718709946,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• ya.',\n",
              "  'token': 290,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.03240565210580826,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• ha.',\n",
              "  'token': 297,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.01638958230614662,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• Liva·ªã.',\n",
              "  'token': 2441,\n",
              "  'token_str': ' Liva·ªã'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka <mask> Haram.\") #= Boko\n"
      ],
      "metadata": {
        "id": "BD8wh6YRmtbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019329de-d2e7-4a22-a4f9-6ab8b4b0c5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.922619104385376,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Boko Haram.',\n",
              "  'token': 2608,\n",
              "  'token_str': ' Boko'},\n",
              " {'score': 0.0041925013065338135,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Man Haram.',\n",
              "  'token': 2136,\n",
              "  'token_str': ' Man'},\n",
              " {'score': 0.00371567509137094,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Manchester Haram.',\n",
              "  'token': 3417,\n",
              "  'token_str': ' Manchester'},\n",
              " {'score': 0.0029909424483776093,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Sa·ª•t Haram.',\n",
              "  'token': 3099,\n",
              "  'token_str': ' Sa·ª•t'},\n",
              " {'score': 0.0027692695148289204,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka soshal Haram.',\n",
              "  'token': 3747,\n",
              "  'token_str': ' soshal'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado <mask> ·ªçh·ª•r·ª• a.\") #= iwu\n"
      ],
      "metadata": {
        "id": "k6sdE6Wemswq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b415234-97de-44c9-ca6f-63ed2961f371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.08747450262308121,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ªçr·ª• ·ªçh·ª•r·ª• a.',\n",
              "  'token': 468,\n",
              "  'token_str': ' ·ªçr·ª•'},\n",
              " {'score': 0.06200091168284416,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ª•wa ·ªçh·ª•r·ª• a.',\n",
              "  'token': 558,\n",
              "  'token_str': ' ·ª•wa'},\n",
              " {'score': 0.047154832631349564,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ªçch·ªãch·ªã ·ªçh·ª•r·ª• a.',\n",
              "  'token': 677,\n",
              "  'token_str': ' ·ªçch·ªãch·ªã'},\n",
              " {'score': 0.03148853778839111,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado iwu ·ªçh·ª•r·ª• a.',\n",
              "  'token': 670,\n",
              "  'token_str': ' iwu'},\n",
              " {'score': 0.029196161776781082,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado obodo ·ªçh·ª•r·ª• a.',\n",
              "  'token': 565,\n",
              "  'token_str': ' obodo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\" <mask> s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.\") #= Buhari\n"
      ],
      "metadata": {
        "id": "X8e7jRBLmrtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d69840-c27d-4ab4-a7b7-27517f698944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.293053537607193,\n",
              "  'sequence': 'A s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 37,\n",
              "  'token_str': 'A'},\n",
              " {'score': 0.23877833783626556,\n",
              "  'sequence': '·ªå s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 337,\n",
              "  'token_str': '·ªå'},\n",
              " {'score': 0.049465473741292953,\n",
              "  'sequence': 'Ha s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 515,\n",
              "  'token_str': 'Ha'},\n",
              " {'score': 0.0299718976020813,\n",
              "  'sequence': 'O s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 51,\n",
              "  'token_str': 'O'},\n",
              " {'score': 0.01546638086438179,\n",
              "  'sequence': 'Any·ªã s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 714,\n",
              "  'token_str': 'Any·ªã'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ala <mask>  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.\") #= Na·ªãjir·ªãa\n"
      ],
      "metadata": {
        "id": "b1uSDAbWmq3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fef3744-d622-42bf-981b-bfdfead2e40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2177654653787613,\n",
              "  'sequence': 'Ala ah·ª•  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 307,\n",
              "  'token_str': ' ah·ª•'},\n",
              " {'score': 0.03414909541606903,\n",
              "  'sequence': 'Ala Nigeria  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 1264,\n",
              "  'token_str': ' Nigeria'},\n",
              " {'score': 0.03212662413716316,\n",
              "  'sequence': 'Ala Igbo  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 854,\n",
              "  'token_str': ' Igbo'},\n",
              " {'score': 0.021992022171616554,\n",
              "  'sequence': 'Ala,  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 16,\n",
              "  'token_str': ','},\n",
              " {'score': 0.015841081738471985,\n",
              "  'sequence': 'Ala a  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbvsFIyNpID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46d02a2-0ec0-4005-9896-5a8a9fdfba07"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"·ªå b·ª• <mask>a ka a na- ar·ªãa .\") #= mmad·ª•\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.032015010714530945,\n",
              "  'sequence': '·ªå b·ª•-a ka a na- ar·ªãa.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.016286971047520638,\n",
              "  'sequence': '·ªå b·ª• nwaa ka a na- ar·ªãa.',\n",
              "  'token': 420,\n",
              "  'token_str': ' nwa'},\n",
              " {'score': 0.009335670620203018,\n",
              "  'sequence': '·ªå b·ª• Nwannaa ka a na- ar·ªãa.',\n",
              "  'token': 1516,\n",
              "  'token_str': ' Nwanna'},\n",
              " {'score': 0.00738544762134552,\n",
              "  'sequence': '·ªå b·ª• ·ªãkwaa ka a na- ar·ªãa.',\n",
              "  'token': 1479,\n",
              "  'token_str': ' ·ªãkwa'},\n",
              " {'score': 0.006971334107220173,\n",
              "  'sequence': '·ªå b·ª• adaa ka a na- ar·ªãa.',\n",
              "  'token': 1050,\n",
              "  'token_str': ' ada'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Hddc-BufgXzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f12d8c-8a0e-43ce-e74a-e1fa7f139d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX7kbLAcJJ6I"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"/content/igbo_bert4.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/igbo_bert4','/content/gdrive/MyDrive/igbo_bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GvyCrVFLwlLZ",
        "outputId": "218fc127-ce6c-4c87-b10f-6a52fa7dbde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/igbo_bert/igbo_bert4'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOLSz2YI4Rv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75222122-fb71-4ffd-e15c-e42eb65139c3"
      },
      "source": [
        "# shutil.make_archive(\"/content/igbo_bert4\", 'zip', \"igbo_bert4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/igbo_bert4.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_save_name = '/igbo_bert4.zip'\n",
        "# path = F\"/content/gdrive/My Drive/igbo_bert/{model_save_name}\"\n",
        "# torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "vfeHNovnVuNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('/content/gdrive/MyDrive/igbo_bert/igbo_bert4','/content/sample_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "f8JYFdP-yoKH",
        "outputId": "c8c6a883-a1bd-49da-f81d-532fafe891ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f51ccd17d763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/igbo_bert/igbo_bert4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/sample_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/gdrive/MyDrive/igbo_bert/igbo_bert4'"
          ]
        }
      ]
    }
  ]
}