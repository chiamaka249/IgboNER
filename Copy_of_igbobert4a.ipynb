{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of  igbobert4a",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOYCYPkMtw4SFau2eXpvMmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiamaka249/IgboNER/blob/main/Copy_of_igbobert4a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4amslz4Oo9vT",
        "outputId": "30a89282-2fbf-4fd4-b8e1-4a404fc6958e"
      },
      "source": [
        "!wget -c https://github.com/IgnatiusEzeani/IGBONLP/raw/master/ig_monoling/text.zip\n",
        "!wget -c https://raw.githubusercontent.com/chiamaka249/lacuna_pos_ner/main/language_corpus/ibo/ibo.txt\n",
        "!wget -c https://github.com/chiamaka249/IgboNER/blob/main/config.json"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 00:45:31--  https://github.com/IgnatiusEzeani/IGBONLP/raw/master/ig_monoling/text.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/IgnatiusEzeani/IGBONLP/master/ig_monoling/text.zip [following]\n",
            "--2021-12-10 00:45:31--  https://raw.githubusercontent.com/IgnatiusEzeani/IGBONLP/master/ig_monoling/text.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7604282 (7.3M) [application/zip]\n",
            "Saving to: ‘text.zip’\n",
            "\n",
            "\rtext.zip              0%[                    ]       0  --.-KB/s               \rtext.zip            100%[===================>]   7.25M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-12-10 00:45:31 (114 MB/s) - ‘text.zip’ saved [7604282/7604282]\n",
            "\n",
            "--2021-12-10 00:45:31--  https://raw.githubusercontent.com/chiamaka249/lacuna_pos_ner/main/language_corpus/ibo/ibo.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1908788 (1.8M) [text/plain]\n",
            "Saving to: ‘ibo.txt’\n",
            "\n",
            "ibo.txt             100%[===================>]   1.82M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-10 00:45:31 (47.7 MB/s) - ‘ibo.txt’ saved [1908788/1908788]\n",
            "\n",
            "--2021-12-10 00:45:31--  https://github.com/chiamaka249/IgboNER/blob/main/config.json\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "config.json             [ <=>                ] 164.94K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-12-10 00:45:32 (6.60 MB/s) - ‘config.json’ saved [168898]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSkvlYoplYP"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "def unzip(zipfilename):\n",
        "  try:\n",
        "    with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(zipfilename[:-4])\n",
        "      return f\"'{zipfilename}' unzipped!\"\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Cannot find '{zipfilename}' file\")\n",
        "\n",
        "unzip(\"text.zip\")\n",
        "!rm text.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua0R2p31p8zA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "176c4225-7d25-48be-8436-255f90117aaa"
      },
      "source": [
        "#copies the file \"ibo.txt\" to into the folder \"text\"\n",
        "import shutil\n",
        "shutil.move('/content/ibo.txt', '/content/text')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/text/ibo.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj4i2-9bp4U3"
      },
      "source": [
        "# import os\n",
        "#import shutil\n",
        "dir_name = \"/content/text\"\n",
        "text=\"\"\n",
        "for fname in os.listdir(dir_name):\n",
        "  fname = os.path.join(dir_name, fname)\n",
        "  with open(fname, \"r\", encoding=\"utf8\") as datafile:\n",
        "    text = text+\"\\n\"+datafile.read()\n",
        "\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf8\") as datafile:\n",
        "  datafile.write(text)\n",
        "\n",
        "shutil.rmtree(\"text\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLhNvJubEowT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb64eedb-a3c6-4c5c-decf-1aa4e8b6c48f"
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "# transformers version at notebook update --- 2.11.0\n",
        "# tokenizers version at notebook update --- 0.8.0rc1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Successfully uninstalled tensorflow-2.7.0\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-x_83yala\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-x_83yala\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 86.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 73.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 662 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.14.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.14.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.14.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.1.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.14.0.dev0-py3-none-any.whl size=3320667 sha256=16209dbd306b3a82a3bf60064b4f4031f080a4916e772f453e1e6c6af9c77c57\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-thu00alc/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.0.dev0\n",
            "tokenizers                    0.10.3\n",
            "transformers                  4.14.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyraD86RE3QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979306ec-4d29-4aa5-894f-f7242bcf8e21"
      },
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19.2 s, sys: 1.24 s, total: 20.4 s\n",
            "Wall time: 5.69 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro52g8BqFFfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba212d25-eea9-437c-f488-ee8e56e21b8f"
      },
      "source": [
        "!mkdir igbo_bert4\n",
        "tokenizer.save_model(\"igbo_bert4\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['igbo_bert4/vocab.json', 'igbo_bert4/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/config.json', '/content/igbo_bert4') "
      ],
      "metadata": {
        "id": "dV-RSECOvfml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5d89500-3308-4c7d-b121-1b20b25aadd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/igbo_bert4/config.json'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekvedLrFR_t"
      },
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./igbo_bert4/vocab.json\",\n",
        "    \"./igbo_bert4/merges.txt\",\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E52LgvLWFbuq"
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nm7h9ndFis2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1772f60a-964b-4555-cf77-2d3369562494"
      },
      "source": [
        "tokenizer.encode(\"Simone gara ụka ụnyahụ guọ egwu ma ga-kwa taa.\").tokens"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'Simone',\n",
              " 'Ġgara',\n",
              " 'Ġá»¥ka',\n",
              " 'Ġá»¥nyahá»¥',\n",
              " 'Ġgu',\n",
              " 'á»į',\n",
              " 'Ġegwu',\n",
              " 'Ġma',\n",
              " 'Ġga',\n",
              " '-',\n",
              " 'kwa',\n",
              " 'Ġtaa',\n",
              " '.',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxcYhcxRKROn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb16d63-16c7-4f47-a5cb-85c50cf060e5"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 10 00:46:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMe5vRLvG5Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe84f90-c3ff-4891-9f4a-32ac9202aa67"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtbKfFgG-Y3"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhCRKUJR65iJ"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqujlqjHQnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b76a426-bef3-4cb5-9103-7e6c0d60f7a8"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./igbo_bert4\", max_len=512)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvup7wl8Hhp9"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyWUosTlHnRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf66f9f-be48-4762-ade0-3b705b70abc4"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 83 million parameters"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hujpbn1oHp-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f75f433-8775-4aaf-b1f8-558365652ba5"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = \"/content/data.txt\",\n",
        "    block_size = 128\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.1 s, sys: 1.23 s, total: 33.4 s\n",
            "Wall time: 15.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EICtSzqwH618"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kalucrRPH9wb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./igbo_bert4\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCWG7CRZIOkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a30927b0-2e41-4ae9-a901-4732b43feb97"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "***** Running training *****\n",
            "  Num examples = 391448\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 30585\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30585' max='30585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30585/30585 3:15:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.383200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.338800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.878500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>4.143100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>3.994600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.892700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.741200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>3.588900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.531100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>3.482900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>3.424600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>3.377600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>3.321800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>3.268500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>3.224100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>3.191700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>3.189900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>3.156800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>3.105400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>3.054300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>3.041500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>3.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>3.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>2.953100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>2.918200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>2.918700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>2.931200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>2.867800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>2.861700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>2.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>2.843800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>2.810500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>2.815100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>2.782600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>2.779300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>2.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>2.752300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>2.720900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>2.703400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>2.714200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>2.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>2.689000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>2.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>2.677800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>2.665200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>2.642600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>2.633900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>2.636400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>2.635800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>2.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>2.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>2.620400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>2.598300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>2.597300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>2.614400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>2.580800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>2.578300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>2.578800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert4/checkpoint-10000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-10000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-10000/pytorch_model.bin\n",
            "Saving model checkpoint to ./igbo_bert4/checkpoint-20000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-20000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-20000/pytorch_model.bin\n",
            "Saving model checkpoint to ./igbo_bert4/checkpoint-30000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-30000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-30000/pytorch_model.bin\n",
            "Deleting older checkpoint [igbo_bert4/checkpoint-10000] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3h 4min, sys: 12min 37s, total: 3h 16min 37s\n",
            "Wall time: 3h 15min 44s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30585, training_loss=3.1495825427798874, metrics={'train_runtime': 11744.2923, 'train_samples_per_second': 166.655, 'train_steps_per_second': 2.604, 'total_flos': 3.365972073574656e+16, 'train_loss': 3.1495825427798874, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkwVjpAyIVu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e38cec0-6eb7-4233-a316-85bd949a9894"
      },
      "source": [
        "trainer.save_model(\"./igbo_bert4\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert4\n",
            "Configuration saved in ./igbo_bert4/config.json\n",
            "Model weights saved in ./igbo_bert4/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYx9FK7ZIYZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b16a208-422f-4bd7-9307-6d7719468aee"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./igbo_bert4\",\n",
        "    tokenizer=\"./igbo_bert4\"\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading weights file ./igbo_bert4/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./igbo_bert4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "Didn't find file ./igbo_bert4/tokenizer.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/added_tokens.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/special_tokens_map.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/tokenizer_config.json. We won't load it.\n",
            "loading file ./igbo_bert4/vocab.json\n",
            "loading file ./igbo_bert4/merges.txt\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQK6jyf9IkRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c256d95-3440-4458-c370-5b612c28f80c"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Abụ m Maazị <mask>.\") #= okafor/Ọkafọ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.036398716270923615,\n",
              "  'sequence': 'Abụ m Maazị Ọkafọ.',\n",
              "  'token': 5307,\n",
              "  'token_str': ' Ọkafọ'},\n",
              " {'score': 0.01226269081234932,\n",
              "  'sequence': 'Abụ m Maazị A.',\n",
              "  'token': 348,\n",
              "  'token_str': ' A'},\n",
              " {'score': 0.010232401080429554,\n",
              "  'sequence': 'Abụ m Maazị O.',\n",
              "  'token': 381,\n",
              "  'token_str': ' O'},\n",
              " {'score': 0.009688876569271088,\n",
              "  'sequence': 'Abụ m Maazị Chineke.',\n",
              "  'token': 394,\n",
              "  'token_str': ' Chineke'},\n",
              " {'score': 0.0048571135848760605,\n",
              "  'sequence': 'Abụ m Maazị M.',\n",
              "  'token': 448,\n",
              "  'token_str': ' M'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mje0nMIoWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2028e99-adef-4e07-ef90-6649cf71eccb"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaanyị na <mask> ji na akara.\") #= eri\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2381240725517273,\n",
              "  'sequence': 'Nwaanyị na ya ji na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.08440182358026505,\n",
              "  'sequence': 'Nwaanyị na nwunye ji na akara.',\n",
              "  'token': 724,\n",
              "  'token_str': ' nwunye'},\n",
              " {'score': 0.07014906406402588,\n",
              "  'sequence': 'Nwaanyị na- ji na akara.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.03455997258424759,\n",
              "  'sequence': 'Nwaanyị na nwaanyị ji na akara.',\n",
              "  'token': 623,\n",
              "  'token_str': ' nwaanyị'},\n",
              " {'score': 0.024705424904823303,\n",
              "  'sequence': 'Nwaanyị na ha ji na akara.',\n",
              "  'token': 296,\n",
              "  'token_str': ' ha'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9wjE8PItpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef13f75-a4fe-45ba-8593-bcd614793680"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Chineke ga- ebibikwa ndị niile na- eme ihe <mask>.\") #=ọjọọ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2959575653076172,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ọjọọ.',\n",
              "  'token': 707,\n",
              "  'token_str': ' ọjọọ'},\n",
              " {'score': 0.12293197959661484,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe niile.',\n",
              "  'token': 427,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.07944665849208832,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe a.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.0650472342967987,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ọma.',\n",
              "  'token': 496,\n",
              "  'token_str': ' ọma'},\n",
              " {'score': 0.035585831850767136,\n",
              "  'sequence': 'Chineke ga- ebibikwa ndị niile na- eme ihe ike.',\n",
              "  'token': 358,\n",
              "  'token_str': ' ike'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubR7pCxJIyNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892658f5-1c68-42e4-a1cc-ddcba5b34596"
      },
      "source": [
        "fill_mask(\"ọba akwụkwọ Ọkammụta Kenneth Dike dị <mask>.\") #n'Awka\n",
        "\n",
        "# This is the beginning of a beautiful <mask>.\n",
        "# =>"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.07655657082796097,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị iche.',\n",
              "  'token': 462,\n",
              "  'token_str': ' iche'},\n",
              " {'score': 0.05872797220945358,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị mkpa.',\n",
              "  'token': 607,\n",
              "  'token_str': ' mkpa'},\n",
              " {'score': 0.050002582371234894,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị icheiche.',\n",
              "  'token': 3738,\n",
              "  'token_str': ' icheiche'},\n",
              " {'score': 0.03505287691950798,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị egwu.',\n",
              "  'token': 705,\n",
              "  'token_str': ' egwu'},\n",
              " {'score': 0.03378322347998619,\n",
              "  'sequence': 'ọba akwụkwọ Ọkammụta Kenneth Dike dị nsọ.',\n",
              "  'token': 715,\n",
              "  'token_str': ' nsọ'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgveMBQYNZV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44db9616-09f4-463f-d56b-5f4d927e7740"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaanyị na eri <mask> na akara.\") #= ji\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.12419361621141434,\n",
              "  'sequence': 'Nwaanyị na eri ya na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.047471560537815094,\n",
              "  'sequence': 'Nwaanyị na eri nri na akara.',\n",
              "  'token': 870,\n",
              "  'token_str': ' nri'},\n",
              " {'score': 0.024701394140720367,\n",
              "  'sequence': 'Nwaanyị na eri ha na akara.',\n",
              "  'token': 296,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.019818346947431564,\n",
              "  'sequence': 'Nwaanyị na eri ego na akara.',\n",
              "  'token': 591,\n",
              "  'token_str': ' ego'},\n",
              " {'score': 0.01857335865497589,\n",
              "  'sequence': 'Nwaanyị na eri ihe na akara.',\n",
              "  'token': 300,\n",
              "  'token_str': ' ihe'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Gaanụ mee ndị <mask> niile ka ha bụrụ ndị na- eso ụzọ m  .\") #= mba\n"
      ],
      "metadata": {
        "id": "-JgRzOtZmTtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51220ef-0711-4f17-abc0-6e43aad54d20"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.36260899901390076,\n",
              "  'sequence': 'Gaanụ mee ndị a niile ka ha bụrụ ndị na- eso ụzọ m .',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.06406810879707336,\n",
              "  'sequence': 'Gaanụ mee ndị mmadụ niile ka ha bụrụ ndị na- eso ụzọ m .',\n",
              "  'token': 393,\n",
              "  'token_str': ' mmadụ'},\n",
              " {'score': 0.06030040606856346,\n",
              "  'sequence': 'Gaanụ mee ndị ọzọ niile ka ha bụrụ ndị na- eso ụzọ m .',\n",
              "  'token': 434,\n",
              "  'token_str': ' ọzọ'},\n",
              " {'score': 0.055031705647706985,\n",
              "  'sequence': 'Gaanụ mee ndị ahụ niile ka ha bụrụ ndị na- eso ụzọ m .',\n",
              "  'token': 310,\n",
              "  'token_str': ' ahụ'},\n",
              " {'score': 0.04922444000840187,\n",
              "  'sequence': 'Gaanụ mee ndị m niile ka ha bụrụ ndị na- eso ụzọ m .',\n",
              "  'token': 268,\n",
              "  'token_str': ' m'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Jehova họpụtara Mozis ka ọ bụrụ onye ndú ụmụ <mask>.\") #= Izrel\n"
      ],
      "metadata": {
        "id": "_zB0aW-cmuQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab86c42-c779-4085-c303-9e6e06477a2c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.3182317912578583,\n",
              "  'sequence': 'Jehova họpụtara Mozis ka ọ bụrụ onye ndú ụmụ ya.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.21329301595687866,\n",
              "  'sequence': 'Jehova họpụtara Mozis ka ọ bụrụ onye ndú ụmụ Izrel.',\n",
              "  'token': 680,\n",
              "  'token_str': ' Izrel'},\n",
              " {'score': 0.20545001327991486,\n",
              "  'sequence': 'Jehova họpụtara Mozis ka ọ bụrụ onye ndú ụmụ mmadụ.',\n",
              "  'token': 393,\n",
              "  'token_str': ' mmadụ'},\n",
              " {'score': 0.04033781215548515,\n",
              "  'sequence': 'Jehova họpụtara Mozis ka ọ bụrụ onye ndú ụmụ ha.',\n",
              "  'token': 296,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.017210429534316063,\n",
              "  'sequence': 'Jehova họpụtara Mozis ka ọ bụrụ onye ndú ụmụ anụmanụ.',\n",
              "  'token': 1601,\n",
              "  'token_str': ' anụmanụ'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ụmụakwụkwọ Chibok anọọla ụbọchị 2000 n’ aka <mask> Haram.\") #= Boko\n"
      ],
      "metadata": {
        "id": "BD8wh6YRmtbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5893ab2-d7db-4662-d71d-ee785514f9b1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8794072866439819,\n",
              "  'sequence': 'Ụmụakwụkwọ Chibok anọọla ụbọchị 2000 n’ aka Boko Haram.',\n",
              "  'token': 2535,\n",
              "  'token_str': ' Boko'},\n",
              " {'score': 0.0101553313434124,\n",
              "  'sequence': 'Ụmụakwụkwọ Chibok anọọla ụbọchị 2000 n’ aka Akwụkwọ Haram.',\n",
              "  'token': 1099,\n",
              "  'token_str': ' Akwụkwọ'},\n",
              " {'score': 0.009289715439081192,\n",
              "  'sequence': 'Ụmụakwụkwọ Chibok anọọla ụbọchị 2000 n’ aka Super Haram.',\n",
              "  'token': 3199,\n",
              "  'token_str': ' Super'},\n",
              " {'score': 0.005499729886651039,\n",
              "  'sequence': 'Ụmụakwụkwọ Chibok anọọla ụbọchị 2000 n’ aka Manchester Haram.',\n",
              "  'token': 3278,\n",
              "  'token_str': ' Manchester'},\n",
              " {'score': 0.003374180756509304,\n",
              "  'sequence': 'Ụmụakwụkwọ Chibok anọọla ụbọchị 2000 n’ aka Man Haram.',\n",
              "  'token': 2024,\n",
              "  'token_str': ' Man'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwunye Gọvanọ Ekiti steeti bụ Bisi Fayemi so na ndị na- akwado <mask> ọhụrụ a.\") #= iwu\n"
      ],
      "metadata": {
        "id": "k6sdE6Wemswq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5d024d-7086-44f0-dce1-6fad69f10b1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.12909017503261566,\n",
              "  'sequence': 'Nwunye Gọvanọ Ekiti steeti bụ Bisi Fayemi so na ndị na- akwado ọrụ ọhụrụ a.',\n",
              "  'token': 477,\n",
              "  'token_str': ' ọrụ'},\n",
              " {'score': 0.05322573706507683,\n",
              "  'sequence': 'Nwunye Gọvanọ Ekiti steeti bụ Bisi Fayemi so na ndị na- akwado ọchịchị ọhụrụ a.',\n",
              "  'token': 719,\n",
              "  'token_str': ' ọchịchị'},\n",
              " {'score': 0.036072392016649246,\n",
              "  'sequence': 'Nwunye Gọvanọ Ekiti steeti bụ Bisi Fayemi so na ndị na- akwado ụlọọrụ ọhụrụ a.',\n",
              "  'token': 1411,\n",
              "  'token_str': ' ụlọọrụ'},\n",
              " {'score': 0.025011051446199417,\n",
              "  'sequence': 'Nwunye Gọvanọ Ekiti steeti bụ Bisi Fayemi so na ndị na- akwado ụka ọhụrụ a.',\n",
              "  'token': 1154,\n",
              "  'token_str': ' ụka'},\n",
              " {'score': 0.023319613188505173,\n",
              "  'sequence': 'Nwunye Gọvanọ Ekiti steeti bụ Bisi Fayemi so na ndị na- akwado obodo ọhụrụ a.',\n",
              "  'token': 576,\n",
              "  'token_str': ' obodo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\" <mask> sị ka ehiwe ụlọikpe pụrụiche maka mpụ.\") #= Buhari\n"
      ],
      "metadata": {
        "id": "X8e7jRBLmrtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58fa2da-0370-497a-8003-50c8558f7a21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.5028418898582458,\n",
              "  'sequence': 'A sị ka ehiwe ụlọikpe pụrụiche maka mpụ.',\n",
              "  'token': 37,\n",
              "  'token_str': 'A'},\n",
              " {'score': 0.20332291722297668,\n",
              "  'sequence': 'Ọ sị ka ehiwe ụlọikpe pụrụiche maka mpụ.',\n",
              "  'token': 336,\n",
              "  'token_str': 'Ọ'},\n",
              " {'score': 0.03303634002804756,\n",
              "  'sequence': 'Ha sị ka ehiwe ụlọikpe pụrụiche maka mpụ.',\n",
              "  'token': 513,\n",
              "  'token_str': 'Ha'},\n",
              " {'score': 0.01529951673001051,\n",
              "  'sequence': 'Igbo sị ka ehiwe ụlọikpe pụrụiche maka mpụ.',\n",
              "  'token': 3656,\n",
              "  'token_str': 'Igbo'},\n",
              " {'score': 0.012158594094216824,\n",
              "  'sequence': 'Ị sị ka ehiwe ụlọikpe pụrụiche maka mpụ.',\n",
              "  'token': 488,\n",
              "  'token_str': 'Ị'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ala <mask>  ga- eweta ezi ọnọdụ nchekwa maka ndị chọrọ ịwebata ego n’ ọrụ ugbo.\") #= Naịjirịa\n"
      ],
      "metadata": {
        "id": "b1uSDAbWmq3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b8f17d-fda1-485a-c755-9e468040190c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1200433224439621,\n",
              "  'sequence': 'Ala ahụ  ga- eweta ezi ọnọdụ nchekwa maka ndị chọrọ ịwebata ego n’ ọrụ ugbo.',\n",
              "  'token': 310,\n",
              "  'token_str': ' ahụ'},\n",
              " {'score': 0.0745198205113411,\n",
              "  'sequence': 'Ala a  ga- eweta ezi ọnọdụ nchekwa maka ndị chọrọ ịwebata ego n’ ọrụ ugbo.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.02661355398595333,\n",
              "  'sequence': 'Ala Nigeria  ga- eweta ezi ọnọdụ nchekwa maka ndị chọrọ ịwebata ego n’ ọrụ ugbo.',\n",
              "  'token': 1570,\n",
              "  'token_str': ' Nigeria'},\n",
              " {'score': 0.0216804351657629,\n",
              "  'sequence': 'Ala niile  ga- eweta ezi ọnọdụ nchekwa maka ndị chọrọ ịwebata ego n’ ọrụ ugbo.',\n",
              "  'token': 427,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.02018386870622635,\n",
              "  'sequence': 'Ala Igbo  ga- eweta ezi ọnọdụ nchekwa maka ndị chọrọ ịwebata ego n’ ọrụ ugbo.',\n",
              "  'token': 900,\n",
              "  'token_str': ' Igbo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbvsFIyNpID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4adc6652-ff16-4798-fcc4-1529c86e51f3"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ọ bụ <mask>a ka a na- arịa .\") #= mmadụ\n",
        "# fill_mask(\"Nwaanyị na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.08720937371253967,\n",
              "  'sequence': 'Ọ bụ-a ka a na- arịa.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.00832695048302412,\n",
              "  'sequence': 'Ọ bụ Nnamdia ka a na- arịa.',\n",
              "  'token': 3283,\n",
              "  'token_str': ' Nnamdi'},\n",
              " {'score': 0.00810943078249693,\n",
              "  'sequence': 'Ọ bụ nwaa ka a na- arịa.',\n",
              "  'token': 419,\n",
              "  'token_str': ' nwa'},\n",
              " {'score': 0.005891024600714445,\n",
              "  'sequence': 'Ọ bụ nwunyea ka a na- arịa.',\n",
              "  'token': 724,\n",
              "  'token_str': ' nwunye'},\n",
              " {'score': 0.004374524112790823,\n",
              "  'sequence': 'Ọ bụ Nwannaa ka a na- arịa.',\n",
              "  'token': 1459,\n",
              "  'token_str': ' Nwanna'}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6O-Q8D7g5eY"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOLSz2YI4Rv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75222122-fb71-4ffd-e15c-e42eb65139c3"
      },
      "source": [
        "shutil.make_archive(\"/content/igbo_bert4\", 'zip', \"igbo_bert4\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/igbo_bert4.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Hddc-BufgXzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bce44c-2a8a-4ac5-ab1c-be8ebe4862c0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = '/igbo_bert4.zip'\n",
        "path = F\"/content/gdrive/My Drive/igbo_bert/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "vfeHNovnVuNP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX7kbLAcJJ6I"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"/content/igbo_bert4.zip\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive/"
      ],
      "metadata": {
        "id": "6KJMkOrGvQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/igbo_bert4','/content/gdrive/MyDrive/igbo_bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GvyCrVFLwlLZ",
        "outputId": "43659eb9-1c03-4980-b518-a0a1685ee831"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/igbo_bert/igbo_bert4'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('/content/gdrive/MyDrive/igbo_bert/igbo_bert4','/content/sample_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "f8JYFdP-yoKH",
        "outputId": "c8c6a883-a1bd-49da-f81d-532fafe891ff"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f51ccd17d763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/igbo_bert/igbo_bert4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/sample_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/gdrive/MyDrive/igbo_bert/igbo_bert4'"
          ]
        }
      ]
    }
  ]
}