{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of  igbobert4a",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOYCYPkMtw4SFau2eXpvMmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiamaka249/IgboNER/blob/main/Copy_of_igbobert4a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4amslz4Oo9vT",
        "outputId": "30a89282-2fbf-4fd4-b8e1-4a404fc6958e"
      },
      "source": [
        "!wget -c https://github.com/IgnatiusEzeani/IGBONLP/raw/master/ig_monoling/text.zip\n",
        "!wget -c https://raw.githubusercontent.com/chiamaka249/lacuna_pos_ner/main/language_corpus/ibo/ibo.txt\n",
        "!wget -c https://github.com/chiamaka249/IgboNER/blob/main/config.json"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 00:45:31--  https://github.com/IgnatiusEzeani/IGBONLP/raw/master/ig_monoling/text.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/IgnatiusEzeani/IGBONLP/master/ig_monoling/text.zip [following]\n",
            "--2021-12-10 00:45:31--  https://raw.githubusercontent.com/IgnatiusEzeani/IGBONLP/master/ig_monoling/text.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7604282 (7.3M) [application/zip]\n",
            "Saving to: ‚Äòtext.zip‚Äô\n",
            "\n",
            "\rtext.zip              0%[                    ]       0  --.-KB/s               \rtext.zip            100%[===================>]   7.25M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-12-10 00:45:31 (114 MB/s) - ‚Äòtext.zip‚Äô saved [7604282/7604282]\n",
            "\n",
            "--2021-12-10 00:45:31--  https://raw.githubusercontent.com/chiamaka249/lacuna_pos_ner/main/language_corpus/ibo/ibo.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1908788 (1.8M) [text/plain]\n",
            "Saving to: ‚Äòibo.txt‚Äô\n",
            "\n",
            "ibo.txt             100%[===================>]   1.82M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-10 00:45:31 (47.7 MB/s) - ‚Äòibo.txt‚Äô saved [1908788/1908788]\n",
            "\n",
            "--2021-12-10 00:45:31--  https://github.com/chiamaka249/IgboNER/blob/main/config.json\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‚Äòconfig.json‚Äô\n",
            "\n",
            "config.json             [ <=>                ] 164.94K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-12-10 00:45:32 (6.60 MB/s) - ‚Äòconfig.json‚Äô saved [168898]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSkvlYoplYP"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "def unzip(zipfilename):\n",
        "  try:\n",
        "    with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(zipfilename[:-4])\n",
        "      return f\"'{zipfilename}' unzipped!\"\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Cannot find '{zipfilename}' file\")\n",
        "\n",
        "unzip(\"text.zip\")\n",
        "!rm text.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua0R2p31p8zA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "176c4225-7d25-48be-8436-255f90117aaa"
      },
      "source": [
        "#copies the file \"ibo.txt\" to into the folder \"text\"\n",
        "import shutil\n",
        "shutil.move('/content/ibo.txt', '/content/text')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/text/ibo.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj4i2-9bp4U3"
      },
      "source": [
        "# import os\n",
        "#import shutil\n",
        "dir_name = \"/content/text\"\n",
        "text=\"\"\n",
        "for fname in os.listdir(dir_name):\n",
        "  fname = os.path.join(dir_name, fname)\n",
        "  with open(fname, \"r\", encoding=\"utf8\") as datafile:\n",
        "    text = text+\"\\n\"+datafile.read()\n",
        "\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf8\") as datafile:\n",
        "  datafile.write(text)\n",
        "\n",
        "shutil.rmtree(\"text\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLhNvJubEowT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb64eedb-a3c6-4c5c-decf-1aa4e8b6c48f"
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "# transformers version at notebook update --- 2.11.0\n",
        "# tokenizers version at notebook update --- 0.8.0rc1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Successfully uninstalled tensorflow-2.7.0\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-x_83yala\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-x_83yala\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 86.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 73.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61 kB 662 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.14.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.14.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.14.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.1.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.14.0.dev0-py3-none-any.whl size=3320667 sha256=16209dbd306b3a82a3bf60064b4f4031f080a4916e772f453e1e6c6af9c77c57\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-thu00alc/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.0.dev0\n",
            "tokenizers                    0.10.3\n",
            "transformers                  4.14.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyraD86RE3QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979306ec-4d29-4aa5-894f-f7242bcf8e21"
      },
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19.2 s, sys: 1.24 s, total: 20.4 s\n",
            "Wall time: 5.69 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro52g8BqFFfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba212d25-eea9-437c-f488-ee8e56e21b8f"
      },
      "source": [
        "!mkdir igbo_bert4\n",
        "tokenizer.save_model(\"igbo_bert4\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['igbo_bert4/vocab.json', 'igbo_bert4/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/config.json', '/content/igbo_bert4') "
      ],
      "metadata": {
        "id": "dV-RSECOvfml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5d89500-3308-4c7d-b121-1b20b25aadd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/igbo_bert4/config.json'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekvedLrFR_t"
      },
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./igbo_bert4/vocab.json\",\n",
        "    \"./igbo_bert4/merges.txt\",\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E52LgvLWFbuq"
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nm7h9ndFis2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1772f60a-964b-4555-cf77-2d3369562494"
      },
      "source": [
        "tokenizer.encode(\"Simone gara ·ª•ka ·ª•nyah·ª• gu·ªç egwu ma ga-kwa taa.\").tokens"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'Simone',\n",
              " 'ƒ†gara',\n",
              " 'ƒ†√°¬ª¬•ka',\n",
              " 'ƒ†√°¬ª¬•nyah√°¬ª¬•',\n",
              " 'ƒ†gu',\n",
              " '√°¬ªƒØ',\n",
              " 'ƒ†egwu',\n",
              " 'ƒ†ma',\n",
              " 'ƒ†ga',\n",
              " '-',\n",
              " 'kwa',\n",
              " 'ƒ†taa',\n",
              " '.',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxcYhcxRKROn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb16d63-16c7-4f47-a5cb-85c50cf060e5"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 10 00:46:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMe5vRLvG5Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe84f90-c3ff-4891-9f4a-32ac9202aa67"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtbKfFgG-Y3"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhCRKUJR65iJ"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqujlqjHQnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b76a426-bef3-4cb5-9103-7e6c0d60f7a8"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./igbo_bert4\", max_len=512)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvup7wl8Hhp9"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyWUosTlHnRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf66f9f-be48-4762-ade0-3b705b70abc4"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 83 million parameters"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hujpbn1oHp-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f75f433-8775-4aaf-b1f8-558365652ba5"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = \"/content/data.txt\",\n",
        "    block_size = 128\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.1 s, sys: 1.23 s, total: 33.4 s\n",
            "Wall time: 15.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EICtSzqwH618"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kalucrRPH9wb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./igbo_bert4\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCWG7CRZIOkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a30927b0-2e41-4ae9-a901-4732b43feb97"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "***** Running training *****\n",
            "  Num examples = 391448\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 30585\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30585' max='30585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30585/30585 3:15:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.383200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.338800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.878500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>4.143100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>3.994600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.892700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.741200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>3.588900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.531100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>3.482900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>3.424600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>3.377600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>3.321800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>3.268500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>3.224100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>3.191700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>3.189900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>3.156800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>3.105400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>3.054300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>3.041500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>3.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>3.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>2.953100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>2.918200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>2.918700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>2.931200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>2.867800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>2.861700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>2.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>2.843800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>2.810500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>2.815100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>2.782600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>2.779300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>2.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>2.752300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>2.720900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>2.703400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>2.714200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>2.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>2.689000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>2.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>2.677800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>2.665200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>2.642600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>2.633900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>2.636400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>2.635800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>2.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>2.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>2.620400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>2.598300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>2.597300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>2.614400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>2.580800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>2.578300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>2.578800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert4/checkpoint-10000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-10000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-10000/pytorch_model.bin\n",
            "Saving model checkpoint to ./igbo_bert4/checkpoint-20000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-20000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-20000/pytorch_model.bin\n",
            "Saving model checkpoint to ./igbo_bert4/checkpoint-30000\n",
            "Configuration saved in ./igbo_bert4/checkpoint-30000/config.json\n",
            "Model weights saved in ./igbo_bert4/checkpoint-30000/pytorch_model.bin\n",
            "Deleting older checkpoint [igbo_bert4/checkpoint-10000] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3h 4min, sys: 12min 37s, total: 3h 16min 37s\n",
            "Wall time: 3h 15min 44s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30585, training_loss=3.1495825427798874, metrics={'train_runtime': 11744.2923, 'train_samples_per_second': 166.655, 'train_steps_per_second': 2.604, 'total_flos': 3.365972073574656e+16, 'train_loss': 3.1495825427798874, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkwVjpAyIVu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e38cec0-6eb7-4233-a316-85bd949a9894"
      },
      "source": [
        "trainer.save_model(\"./igbo_bert4\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./igbo_bert4\n",
            "Configuration saved in ./igbo_bert4/config.json\n",
            "Model weights saved in ./igbo_bert4/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYx9FK7ZIYZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b16a208-422f-4bd7-9307-6d7719468aee"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./igbo_bert4\",\n",
        "    tokenizer=\"./igbo_bert4\"\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading weights file ./igbo_bert4/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./igbo_bert4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "Didn't find file ./igbo_bert4/tokenizer.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/added_tokens.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/special_tokens_map.json. We won't load it.\n",
            "Didn't find file ./igbo_bert4/tokenizer_config.json. We won't load it.\n",
            "loading file ./igbo_bert4/vocab.json\n",
            "loading file ./igbo_bert4/merges.txt\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./igbo_bert4/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./igbo_bert4\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQK6jyf9IkRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c256d95-3440-4458-c370-5b612c28f80c"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ab·ª• m Maaz·ªã <mask>.\") #= okafor/·ªåkaf·ªç\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.036398716270923615,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã ·ªåkaf·ªç.',\n",
              "  'token': 5307,\n",
              "  'token_str': ' ·ªåkaf·ªç'},\n",
              " {'score': 0.01226269081234932,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã A.',\n",
              "  'token': 348,\n",
              "  'token_str': ' A'},\n",
              " {'score': 0.010232401080429554,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã O.',\n",
              "  'token': 381,\n",
              "  'token_str': ' O'},\n",
              " {'score': 0.009688876569271088,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã Chineke.',\n",
              "  'token': 394,\n",
              "  'token_str': ' Chineke'},\n",
              " {'score': 0.0048571135848760605,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã M.',\n",
              "  'token': 448,\n",
              "  'token_str': ' M'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mje0nMIoWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2028e99-adef-4e07-ef90-6649cf71eccb"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #= eri\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2381240725517273,\n",
              "  'sequence': 'Nwaany·ªã na ya ji na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.08440182358026505,\n",
              "  'sequence': 'Nwaany·ªã na nwunye ji na akara.',\n",
              "  'token': 724,\n",
              "  'token_str': ' nwunye'},\n",
              " {'score': 0.07014906406402588,\n",
              "  'sequence': 'Nwaany·ªã na- ji na akara.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.03455997258424759,\n",
              "  'sequence': 'Nwaany·ªã na nwaany·ªã ji na akara.',\n",
              "  'token': 623,\n",
              "  'token_str': ' nwaany·ªã'},\n",
              " {'score': 0.024705424904823303,\n",
              "  'sequence': 'Nwaany·ªã na ha ji na akara.',\n",
              "  'token': 296,\n",
              "  'token_str': ' ha'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9wjE8PItpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef13f75-a4fe-45ba-8593-bcd614793680"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Chineke ga- ebibikwa nd·ªã niile na- eme ihe <mask>.\") #=·ªçj·ªç·ªç\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2959575653076172,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ·ªçj·ªç·ªç.',\n",
              "  'token': 707,\n",
              "  'token_str': ' ·ªçj·ªç·ªç'},\n",
              " {'score': 0.12293197959661484,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe niile.',\n",
              "  'token': 427,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.07944665849208832,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe a.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.0650472342967987,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ·ªçma.',\n",
              "  'token': 496,\n",
              "  'token_str': ' ·ªçma'},\n",
              " {'score': 0.035585831850767136,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ike.',\n",
              "  'token': 358,\n",
              "  'token_str': ' ike'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubR7pCxJIyNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892658f5-1c68-42e4-a1cc-ddcba5b34596"
      },
      "source": [
        "fill_mask(\"·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã <mask>.\") #n'Awka\n",
        "\n",
        "# This is the beginning of a beautiful <mask>.\n",
        "# =>"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.07655657082796097,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã iche.',\n",
              "  'token': 462,\n",
              "  'token_str': ' iche'},\n",
              " {'score': 0.05872797220945358,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã mkpa.',\n",
              "  'token': 607,\n",
              "  'token_str': ' mkpa'},\n",
              " {'score': 0.050002582371234894,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã icheiche.',\n",
              "  'token': 3738,\n",
              "  'token_str': ' icheiche'},\n",
              " {'score': 0.03505287691950798,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã egwu.',\n",
              "  'token': 705,\n",
              "  'token_str': ' egwu'},\n",
              " {'score': 0.03378322347998619,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã ns·ªç.',\n",
              "  'token': 715,\n",
              "  'token_str': ' ns·ªç'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgveMBQYNZV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44db9616-09f4-463f-d56b-5f4d927e7740"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaany·ªã na eri <mask> na akara.\") #= ji\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.12419361621141434,\n",
              "  'sequence': 'Nwaany·ªã na eri ya na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.047471560537815094,\n",
              "  'sequence': 'Nwaany·ªã na eri nri na akara.',\n",
              "  'token': 870,\n",
              "  'token_str': ' nri'},\n",
              " {'score': 0.024701394140720367,\n",
              "  'sequence': 'Nwaany·ªã na eri ha na akara.',\n",
              "  'token': 296,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.019818346947431564,\n",
              "  'sequence': 'Nwaany·ªã na eri ego na akara.',\n",
              "  'token': 591,\n",
              "  'token_str': ' ego'},\n",
              " {'score': 0.01857335865497589,\n",
              "  'sequence': 'Nwaany·ªã na eri ihe na akara.',\n",
              "  'token': 300,\n",
              "  'token_str': ' ihe'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Gaan·ª• mee nd·ªã <mask> niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m  .\") #= mba\n"
      ],
      "metadata": {
        "id": "-JgRzOtZmTtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51220ef-0711-4f17-abc0-6e43aad54d20"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.36260899901390076,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã a niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.06406810879707336,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã mmad·ª• niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 393,\n",
              "  'token_str': ' mmad·ª•'},\n",
              " {'score': 0.06030040606856346,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã ·ªçz·ªç niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 434,\n",
              "  'token_str': ' ·ªçz·ªç'},\n",
              " {'score': 0.055031705647706985,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã ah·ª• niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 310,\n",
              "  'token_str': ' ah·ª•'},\n",
              " {'score': 0.04922444000840187,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã m niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 268,\n",
              "  'token_str': ' m'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• <mask>.\") #= Izrel\n"
      ],
      "metadata": {
        "id": "_zB0aW-cmuQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab86c42-c779-4085-c303-9e6e06477a2c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.3182317912578583,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• ya.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.21329301595687866,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• Izrel.',\n",
              "  'token': 680,\n",
              "  'token_str': ' Izrel'},\n",
              " {'score': 0.20545001327991486,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• mmad·ª•.',\n",
              "  'token': 393,\n",
              "  'token_str': ' mmad·ª•'},\n",
              " {'score': 0.04033781215548515,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• ha.',\n",
              "  'token': 296,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.017210429534316063,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• an·ª•man·ª•.',\n",
              "  'token': 1601,\n",
              "  'token_str': ' an·ª•man·ª•'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka <mask> Haram.\") #= Boko\n"
      ],
      "metadata": {
        "id": "BD8wh6YRmtbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5893ab2-d7db-4662-d71d-ee785514f9b1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8794072866439819,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Boko Haram.',\n",
              "  'token': 2535,\n",
              "  'token_str': ' Boko'},\n",
              " {'score': 0.0101553313434124,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Akw·ª•kw·ªç Haram.',\n",
              "  'token': 1099,\n",
              "  'token_str': ' Akw·ª•kw·ªç'},\n",
              " {'score': 0.009289715439081192,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Super Haram.',\n",
              "  'token': 3199,\n",
              "  'token_str': ' Super'},\n",
              " {'score': 0.005499729886651039,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Manchester Haram.',\n",
              "  'token': 3278,\n",
              "  'token_str': ' Manchester'},\n",
              " {'score': 0.003374180756509304,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Man Haram.',\n",
              "  'token': 2024,\n",
              "  'token_str': ' Man'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado <mask> ·ªçh·ª•r·ª• a.\") #= iwu\n"
      ],
      "metadata": {
        "id": "k6sdE6Wemswq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5d024d-7086-44f0-dce1-6fad69f10b1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.12909017503261566,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ªçr·ª• ·ªçh·ª•r·ª• a.',\n",
              "  'token': 477,\n",
              "  'token_str': ' ·ªçr·ª•'},\n",
              " {'score': 0.05322573706507683,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ªçch·ªãch·ªã ·ªçh·ª•r·ª• a.',\n",
              "  'token': 719,\n",
              "  'token_str': ' ·ªçch·ªãch·ªã'},\n",
              " {'score': 0.036072392016649246,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ª•l·ªç·ªçr·ª• ·ªçh·ª•r·ª• a.',\n",
              "  'token': 1411,\n",
              "  'token_str': ' ·ª•l·ªç·ªçr·ª•'},\n",
              " {'score': 0.025011051446199417,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ª•ka ·ªçh·ª•r·ª• a.',\n",
              "  'token': 1154,\n",
              "  'token_str': ' ·ª•ka'},\n",
              " {'score': 0.023319613188505173,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado obodo ·ªçh·ª•r·ª• a.',\n",
              "  'token': 576,\n",
              "  'token_str': ' obodo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\" <mask> s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.\") #= Buhari\n"
      ],
      "metadata": {
        "id": "X8e7jRBLmrtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58fa2da-0370-497a-8003-50c8558f7a21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.5028418898582458,\n",
              "  'sequence': 'A s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 37,\n",
              "  'token_str': 'A'},\n",
              " {'score': 0.20332291722297668,\n",
              "  'sequence': '·ªå s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 336,\n",
              "  'token_str': '·ªå'},\n",
              " {'score': 0.03303634002804756,\n",
              "  'sequence': 'Ha s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 513,\n",
              "  'token_str': 'Ha'},\n",
              " {'score': 0.01529951673001051,\n",
              "  'sequence': 'Igbo s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 3656,\n",
              "  'token_str': 'Igbo'},\n",
              " {'score': 0.012158594094216824,\n",
              "  'sequence': '·ªä s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 488,\n",
              "  'token_str': '·ªä'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ala <mask>  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.\") #= Na·ªãjir·ªãa\n"
      ],
      "metadata": {
        "id": "b1uSDAbWmq3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b8f17d-fda1-485a-c755-9e468040190c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1200433224439621,\n",
              "  'sequence': 'Ala ah·ª•  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 310,\n",
              "  'token_str': ' ah·ª•'},\n",
              " {'score': 0.0745198205113411,\n",
              "  'sequence': 'Ala a  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.02661355398595333,\n",
              "  'sequence': 'Ala Nigeria  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 1570,\n",
              "  'token_str': ' Nigeria'},\n",
              " {'score': 0.0216804351657629,\n",
              "  'sequence': 'Ala niile  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 427,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.02018386870622635,\n",
              "  'sequence': 'Ala Igbo  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 900,\n",
              "  'token_str': ' Igbo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbvsFIyNpID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4adc6652-ff16-4798-fcc4-1529c86e51f3"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"·ªå b·ª• <mask>a ka a na- ar·ªãa .\") #= mmad·ª•\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.08720937371253967,\n",
              "  'sequence': '·ªå b·ª•-a ka a na- ar·ªãa.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.00832695048302412,\n",
              "  'sequence': '·ªå b·ª• Nnamdia ka a na- ar·ªãa.',\n",
              "  'token': 3283,\n",
              "  'token_str': ' Nnamdi'},\n",
              " {'score': 0.00810943078249693,\n",
              "  'sequence': '·ªå b·ª• nwaa ka a na- ar·ªãa.',\n",
              "  'token': 419,\n",
              "  'token_str': ' nwa'},\n",
              " {'score': 0.005891024600714445,\n",
              "  'sequence': '·ªå b·ª• nwunyea ka a na- ar·ªãa.',\n",
              "  'token': 724,\n",
              "  'token_str': ' nwunye'},\n",
              " {'score': 0.004374524112790823,\n",
              "  'sequence': '·ªå b·ª• Nwannaa ka a na- ar·ªãa.',\n",
              "  'token': 1459,\n",
              "  'token_str': ' Nwanna'}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6O-Q8D7g5eY"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOLSz2YI4Rv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75222122-fb71-4ffd-e15c-e42eb65139c3"
      },
      "source": [
        "shutil.make_archive(\"/content/igbo_bert4\", 'zip', \"igbo_bert4\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/igbo_bert4.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Hddc-BufgXzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bce44c-2a8a-4ac5-ab1c-be8ebe4862c0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = '/igbo_bert4.zip'\n",
        "path = F\"/content/gdrive/My Drive/igbo_bert/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "vfeHNovnVuNP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX7kbLAcJJ6I"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"/content/igbo_bert4.zip\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive/"
      ],
      "metadata": {
        "id": "6KJMkOrGvQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/igbo_bert4','/content/gdrive/MyDrive/igbo_bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GvyCrVFLwlLZ",
        "outputId": "43659eb9-1c03-4980-b518-a0a1685ee831"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/igbo_bert/igbo_bert4'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('/content/gdrive/MyDrive/igbo_bert/igbo_bert4','/content/sample_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "f8JYFdP-yoKH",
        "outputId": "c8c6a883-a1bd-49da-f81d-532fafe891ff"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f51ccd17d763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/igbo_bert/igbo_bert4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/sample_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/gdrive/MyDrive/igbo_bert/igbo_bert4'"
          ]
        }
      ]
    }
  ]
}